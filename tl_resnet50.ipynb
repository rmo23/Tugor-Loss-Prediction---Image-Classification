{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tl_resnet50.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5zVtu3VN8v0g","colab_type":"code","outputId":"df7a155f-ac70-4f30-d136-da4028dce899","executionInfo":{"status":"ok","timestamp":1574694891695,"user_tz":300,"elapsed":25762,"user":{"displayName":"Sharvari Natu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD3HrRjgWlAoNVxnazj4qI2R9Ls5fjMdQfX8ijf=s64","userId":"09254434528500133445"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0a-30QsP9Pgg","colab_type":"text"},"source":["Data Statistics:"]},{"cell_type":"code","metadata":{"id":"KfAjJXJ_824y","colab_type":"code","colab":{}},"source":["# import os \n","# train_data_folder = \"/content/drive/My Drive/NN-ProjectC/Project_C1/Final/Training\"\n","# data_count = 0\n","# for image in os.listdir(train_data_folder):\n","#   if not image.endswith(\".jpg\"):\n","#     print (\"Class\", image,\":\", len(os.listdir(os.path.join(train_data_folder, image))))\n","#   else:\n","#     data_count += 1\n","\n","# print (\"Total number of images: \", data_count)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdpIxmTJ-4ZK","colab_type":"code","colab":{}},"source":["# ! pip install split-folders\n","\n","# import split_folders\n","# training_data_folder = \"/content/drive/My Drive/NN-ProjectC/Project_C1/Final/Training\"\n","# split_folders.ratio(training_data_folder, output = \"train_val_noaug\", seed=1337, ratio = (.7,.3))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaamiU-D-RxZ","colab_type":"code","outputId":"59c201d2-f8e5-4a57-b9f5-034aec57b9f0","executionInfo":{"status":"ok","timestamp":1574652394301,"user_tz":300,"elapsed":2219,"user":{"displayName":"Sharvari Natu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD3HrRjgWlAoNVxnazj4qI2R9Ls5fjMdQfX8ijf=s64","userId":"09254434528500133445"}},"colab":{"base_uri":"https://localhost:8080/","height":799}},"source":["from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import Input\n","\n","\n","HEIGHT = 224\n","WIDTH = 224\n","input_tensor = Input(shape = (HEIGHT, WIDTH, 3))\n","base_model = VGG16(weights = 'imagenet', \n","                      include_top = False, \n","                      input_tensor = input_tensor)\n","\n","# To see the models' architecture and layer names, run the following\n","base_model.summary()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lqfTA1ZgCdCa","colab_type":"code","outputId":"7626f8ac-1999-4aca-ce6d-03a56d8c366c","executionInfo":{"status":"ok","timestamp":1574652394305,"user_tz":300,"elapsed":2200,"user":{"displayName":"Sharvari Natu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD3HrRjgWlAoNVxnazj4qI2R9Ls5fjMdQfX8ijf=s64","userId":"09254434528500133445"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","\n","TRAIN_DIR = train_data_folder = \"/content/drive/My Drive/NN-ProjectC/Project_C1/train_val_noaug/train\"\n","VAL_DIR = \"/content/drive/My Drive/NN-ProjectC/Project_C1/train_val_noaug/val\"\n","HEIGHT = 224\n","WIDTH = 224\n","BATCH_SIZE = 8\n","\n","train_datagen =  ImageDataGenerator(\n","      preprocessing_function=preprocess_input,\n","      rotation_range=90,\n","      horizontal_flip=True,\n","      vertical_flip=True\n","    )\n","\n","\n","\n","train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n","                                                    target_size=(HEIGHT, WIDTH), \n","                                                    batch_size=BATCH_SIZE, class_mode = 'categorical')\n","\n","validation_generator = train_datagen.flow_from_directory( VAL_DIR, \n","                                                         target_size =(HEIGHT, WIDTH), \n","                                                         batch_size = BATCH_SIZE, class_mode = 'categorical', shuffle = False) \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 625 images belonging to 5 classes.\n","Found 271 images belonging to 5 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wf_9E3e5EQTx","colab_type":"code","colab":{}},"source":["\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n","\n","def get_callbacks():\n","\n","   path_checkpoint ='checkpoint_keras'  \n","   log_dir='logs'\n","   \n","   callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n","                                         monitor='val_loss',\n","                                         verbose=1,\n","                                         save_weights_only=False,\n","                                         save_best_only=True,\n","                                         mode='max',\n","                                         period=1)\n","   callback_early_stopping = EarlyStopping(monitor='val_loss',\n","                                           patience=5,\n","                                           verbose=1)\n","   callback_tensorboard = TensorBoard(log_dir=log_dir,\n","                                      histogram_freq=0,\n","                                      write_graph=False)\n","   callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n","                                          factor=0.1,\n","                                          min_lr=1e-4,\n","                                          patience=3,\n","                                          verbose=1)\n","\n","   callbacks = [callback_checkpoint, callback_tensorboard, callback_reduce_lr]\n","\n","   return callbacks\n","\n","from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n","from tensorflow.keras.models import Sequential, Model\n","\n","def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n","    '''for layer in base_model.layers:\n","        layer.trainable = False\n","    '''\n","    x = base_model.output\n","    x = Flatten()(x)\n","    for fc in fc_layers:\n","        # New FC layer, random init\n","        x = Dense(fc, activation='relu')(x) \n","        x = Dropout(dropout)(x)\n","\n","    # New softmax layer\n","    predictions = Dense(num_classes, activation='softmax')(x) \n","    \n","    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n","\n","    return finetune_model\n","\n","class_list = [0, 1, 2, 3, 4]\n","FC_LAYERS = [1024, 1024]\n","dropout = 0.25\n","\n","'''finetune_model = build_finetune_model(base_model, \n","                                      dropout=dropout, \n","                                      fc_layers=FC_LAYERS, \n","                                      num_classes=len(class_list))\n","'''\n","for layer in base_model.layers:\n","  layer.trainable = True\n","\n","# for layer in base_model.layers:\n","#   print (layer, layer.trainable)\n","\n","model = Sequential()\n","model.add(base_model)\n","model.add(Flatten())\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dropout(0.5))\n","# model.add(Dense(100, activation='relu'))\n","# model.add(Dropout(0.5))\n","model.add(Dense(5, activation='softmax'))\n"," \n","# Show a summary of the model. Check the number of trainable parameters\n","# model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iNH5oUwQF49x","colab_type":"code","colab":{}},"source":["# Plot the training and validation loss + accuracy\n","def plot_training(history):\n","    acc = history.history['acc']\n","    val_acc = history.history['val_acc']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    epochs = range(len(acc))\n","\n","    plt.plot(epochs, acc, 'r.')\n","    plt.plot(epochs, val_acc, 'r')\n","    plt.title('Training and validation accuracy')\n","\n","    # plt.figure()\n","    # plt.plot(epochs, loss, 'r.')\n","    # plt.plot(epochs, val_loss, 'r-')\n","    # plt.title('Training and validation loss')\n","    plt.show()\n","\n","    plt.savefig('acc_vs_epochs.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R5_VHZ_BFnFP","colab_type":"code","outputId":"1dff7c55-516c-4231-cc06-5dc8ab2cf4bf","executionInfo":{"status":"ok","timestamp":1574669522960,"user_tz":300,"elapsed":19582,"user":{"displayName":"Sharvari Natu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD3HrRjgWlAoNVxnazj4qI2R9Ls5fjMdQfX8ijf=s64","userId":"09254434528500133445"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from tensorflow.keras.optimizers import SGD, Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","\n","NUM_EPOCHS = 100\n","BATCH_SIZE = 8\n","num_train_images = 625 \n","num_val_images = 271\n","\n","adam = Adam(lr=0.0001)\n","model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","filepath = \"vgg16\" + \"_model_weights.h5\"\n","checkpoint = ModelCheckpoint(filepath, monitor=[\"val_loss\"], verbose=1, mode='max')\n","callbacks_list = get_callbacks()\n","\n","history = model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers = 8,\n","                                       steps_per_epoch = num_train_images // BATCH_SIZE,\n","                                       validation_data = validation_generator, \n","                                       validation_steps = num_val_images// BATCH_SIZE,  \n","                                       shuffle = True, callbacks = [checkpoint])\n","\n","# history = model.fit(train_generator, \n","#                               epochs=NUM_EPOCHS,\n","#                               validation_data = validation_generator, \n","#                               shuffle = True, \n","#                               # batch_size = BATCH_SIZE,\n","#                               callbacks = callbacks_list)\n","\n","\n","plot_training(history)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n","Epoch 1/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3459 - acc: 0.8588Epoch 1/300\n","33/78 [===========>..................] - ETA: 10s - loss: 0.7329 - acc: 0.7652\n","Epoch 00001: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 45s 578ms/step - loss: 0.3502 - acc: 0.8590 - val_loss: 0.7329 - val_acc: 0.7652\n","Epoch 2/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3981 - acc: 0.8489Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6517 - acc: 0.7841\n","Epoch 00002: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.4026 - acc: 0.8460 - val_loss: 0.6517 - val_acc: 0.7841\n","Epoch 3/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3156 - acc: 0.8801Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.5223 - acc: 0.8068\n","Epoch 00003: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.3199 - acc: 0.8768 - val_loss: 0.5223 - val_acc: 0.8068\n","Epoch 4/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3087 - acc: 0.8752Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5703 - acc: 0.7689\n","Epoch 00004: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.3064 - acc: 0.8768 - val_loss: 0.5703 - val_acc: 0.7689\n","Epoch 5/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3186 - acc: 0.8851Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6126 - acc: 0.7765\n","Epoch 00005: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.3198 - acc: 0.8833 - val_loss: 0.6126 - val_acc: 0.7765\n","Epoch 6/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3635 - acc: 0.8637Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6652 - acc: 0.7652\n","Epoch 00006: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.3624 - acc: 0.8639 - val_loss: 0.6652 - val_acc: 0.7652\n","Epoch 7/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8588Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6757 - acc: 0.7727\n","Epoch 00007: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.3404 - acc: 0.8574 - val_loss: 0.6757 - val_acc: 0.7727\n","Epoch 8/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2861 - acc: 0.9031Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6497 - acc: 0.7803\n","Epoch 00008: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.2864 - acc: 0.9028 - val_loss: 0.6497 - val_acc: 0.7803\n","Epoch 9/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3038 - acc: 0.8801Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6207 - acc: 0.7803\n","Epoch 00009: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.3008 - acc: 0.8817 - val_loss: 0.6207 - val_acc: 0.7803\n","Epoch 10/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3176 - acc: 0.8867Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5669 - acc: 0.8220\n","Epoch 00010: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.3147 - acc: 0.8882 - val_loss: 0.5669 - val_acc: 0.8220\n","Epoch 11/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2555 - acc: 0.8933Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5390 - acc: 0.8144\n","Epoch 00011: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.2564 - acc: 0.8930 - val_loss: 0.5390 - val_acc: 0.8144\n","Epoch 12/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9146Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9523 - acc: 0.7803\n","Epoch 00012: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.2140 - acc: 0.9141 - val_loss: 0.9523 - val_acc: 0.7803\n","Epoch 13/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.9010Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6603 - acc: 0.7917\n","Epoch 00013: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.2573 - acc: 0.9006 - val_loss: 0.6603 - val_acc: 0.7917\n","Epoch 14/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2571 - acc: 0.8920Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6264 - acc: 0.7614\n","Epoch 00014: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.2556 - acc: 0.8918 - val_loss: 0.6264 - val_acc: 0.7614\n","Epoch 15/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2738 - acc: 0.8768Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6908 - acc: 0.7803\n","Epoch 00015: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.2708 - acc: 0.8784 - val_loss: 0.6908 - val_acc: 0.7803\n","Epoch 16/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3292 - acc: 0.8801Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6514 - acc: 0.7841\n","Epoch 00016: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.3325 - acc: 0.8801 - val_loss: 0.6514 - val_acc: 0.7841\n","Epoch 17/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2505 - acc: 0.9140Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6117 - acc: 0.7879\n","Epoch 00017: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 547ms/step - loss: 0.2483 - acc: 0.9151 - val_loss: 0.6117 - val_acc: 0.7879\n","Epoch 18/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2333 - acc: 0.9120Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6881 - acc: 0.7917\n","Epoch 00018: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.2334 - acc: 0.9115 - val_loss: 0.6881 - val_acc: 0.7917\n","Epoch 19/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2571 - acc: 0.9010Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0314 - acc: 0.7614\n","Epoch 00019: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 544ms/step - loss: 0.2562 - acc: 0.9006 - val_loss: 1.0314 - val_acc: 0.7614\n","Epoch 20/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9186Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6242 - acc: 0.8258\n","Epoch 00020: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.2135 - acc: 0.9164 - val_loss: 0.6242 - val_acc: 0.8258\n","Epoch 21/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2816 - acc: 0.9048Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6304 - acc: 0.7955\n","Epoch 00021: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.2838 - acc: 0.9044 - val_loss: 0.6304 - val_acc: 0.7955\n","Epoch 22/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2597 - acc: 0.9015Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5546 - acc: 0.7917\n","Epoch 00022: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.2583 - acc: 0.9011 - val_loss: 0.5546 - val_acc: 0.7917\n","Epoch 23/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9058Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6834 - acc: 0.7917\n","Epoch 00023: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.2061 - acc: 0.9038 - val_loss: 0.6834 - val_acc: 0.7917\n","Epoch 24/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9452Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7162 - acc: 0.7841\n","Epoch 00024: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.1827 - acc: 0.9426 - val_loss: 0.7162 - val_acc: 0.7841\n","Epoch 25/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3144 - acc: 0.8961Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6203 - acc: 0.7992\n","Epoch 00025: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.3111 - acc: 0.8974 - val_loss: 0.6203 - val_acc: 0.7992\n","Epoch 26/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.8821Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6099 - acc: 0.8106\n","Epoch 00026: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.3144 - acc: 0.8836 - val_loss: 0.6099 - val_acc: 0.8106\n","Epoch 27/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9573Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0341 - acc: 0.8106\n","Epoch 00027: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 544ms/step - loss: 0.1277 - acc: 0.9579 - val_loss: 1.0341 - val_acc: 0.8106\n","Epoch 28/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3676 - acc: 0.8818Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6429 - acc: 0.7803\n","Epoch 00028: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.3645 - acc: 0.8833 - val_loss: 0.6429 - val_acc: 0.7803\n","Epoch 29/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9195Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5488 - acc: 0.8295\n","Epoch 00029: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.1916 - acc: 0.9206 - val_loss: 0.5488 - val_acc: 0.8295\n","Epoch 30/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9163Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5368 - acc: 0.8333\n","Epoch 00030: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.2266 - acc: 0.9173 - val_loss: 0.5368 - val_acc: 0.8333\n","Epoch 31/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2412 - acc: 0.9097Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9567 - acc: 0.7462\n","Epoch 00031: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.2434 - acc: 0.9092 - val_loss: 0.9567 - val_acc: 0.7462\n","Epoch 32/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9383Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7234 - acc: 0.7765\n","Epoch 00032: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.1973 - acc: 0.9375 - val_loss: 0.7234 - val_acc: 0.7765\n","Epoch 33/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2215 - acc: 0.9120Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6818 - acc: 0.7955\n","Epoch 00033: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 533ms/step - loss: 0.2190 - acc: 0.9131 - val_loss: 0.6818 - val_acc: 0.7955\n","Epoch 34/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1641 - acc: 0.9351Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5993 - acc: 0.8258\n","Epoch 00034: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.1621 - acc: 0.9359 - val_loss: 0.5993 - val_acc: 0.8258\n","Epoch 35/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9442Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5181 - acc: 0.8409\n","Epoch 00035: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.1321 - acc: 0.9449 - val_loss: 0.5181 - val_acc: 0.8409\n","Epoch 36/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9540Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6851 - acc: 0.8030\n","Epoch 00036: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1319 - acc: 0.9514 - val_loss: 0.6851 - val_acc: 0.8030\n","Epoch 37/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9360Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7233 - acc: 0.7614\n","Epoch 00037: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.1723 - acc: 0.9352 - val_loss: 0.7233 - val_acc: 0.7614\n","Epoch 38/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9245Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7723 - acc: 0.7879\n","Epoch 00038: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.1766 - acc: 0.9254 - val_loss: 0.7723 - val_acc: 0.7879\n","Epoch 39/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2268 - acc: 0.9245Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.5299 - acc: 0.8220\n","Epoch 00039: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.2248 - acc: 0.9254 - val_loss: 0.5299 - val_acc: 0.8220\n","Epoch 40/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9601Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8252 - acc: 0.7955\n","Epoch 00040: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1018 - acc: 0.9607 - val_loss: 0.8252 - val_acc: 0.7955\n","Epoch 41/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9464Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7469 - acc: 0.8144\n","Epoch 00041: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.1456 - acc: 0.9439 - val_loss: 0.7469 - val_acc: 0.8144\n","Epoch 42/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9458Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6231 - acc: 0.8295\n","Epoch 00042: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.1456 - acc: 0.9465 - val_loss: 0.6231 - val_acc: 0.8295\n","Epoch 43/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.6985 - acc: 0.7931Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7618 - acc: 0.7083\n","Epoch 00043: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.6939 - acc: 0.7942 - val_loss: 0.7618 - val_acc: 0.7083\n","Epoch 44/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.4410 - acc: 0.8227Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7393 - acc: 0.7424\n","Epoch 00044: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.4365 - acc: 0.8250 - val_loss: 0.7393 - val_acc: 0.7424\n","Epoch 45/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3000 - acc: 0.9064Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6723 - acc: 0.7879\n","Epoch 00045: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.2994 - acc: 0.9060 - val_loss: 0.6723 - val_acc: 0.7879\n","Epoch 46/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9120Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9542 - acc: 0.7614\n","Epoch 00046: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.2157 - acc: 0.9115 - val_loss: 0.9542 - val_acc: 0.7614\n","Epoch 47/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9481Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6158 - acc: 0.8106\n","Epoch 00047: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 545ms/step - loss: 0.1776 - acc: 0.9471 - val_loss: 0.6158 - val_acc: 0.8106\n","Epoch 48/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9153Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7047 - acc: 0.8144\n","Epoch 00048: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.2219 - acc: 0.9164 - val_loss: 0.7047 - val_acc: 0.8144\n","Epoch 49/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9195Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5540 - acc: 0.8182\n","Epoch 00049: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.2545 - acc: 0.9190 - val_loss: 0.5540 - val_acc: 0.8182\n","Epoch 50/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9399Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6378 - acc: 0.8220\n","Epoch 00050: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 545ms/step - loss: 0.2038 - acc: 0.9407 - val_loss: 0.6378 - val_acc: 0.8220\n","Epoch 51/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9402Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6556 - acc: 0.7992\n","Epoch 00051: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.1428 - acc: 0.9410 - val_loss: 0.6556 - val_acc: 0.7992\n","Epoch 52/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1809 - acc: 0.9392Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.6796 - acc: 0.7159\n","Epoch 00052: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.2035 - acc: 0.9352 - val_loss: 1.6796 - val_acc: 0.7159\n","Epoch 53/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3147 - acc: 0.9075Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5543 - acc: 0.8030\n","Epoch 00053: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 549ms/step - loss: 0.3115 - acc: 0.9087 - val_loss: 0.5543 - val_acc: 0.8030\n","Epoch 54/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9458Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6701 - acc: 0.7992\n","Epoch 00054: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1310 - acc: 0.9449 - val_loss: 0.6701 - val_acc: 0.7992\n","Epoch 55/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9688Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8488 - acc: 0.7917\n","Epoch 00055: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0957 - acc: 0.9692 - val_loss: 0.8488 - val_acc: 0.7917\n","Epoch 56/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9524Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7458 - acc: 0.7955\n","Epoch 00056: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.1227 - acc: 0.9530 - val_loss: 0.7458 - val_acc: 0.7955\n","Epoch 57/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9668Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5681 - acc: 0.8295\n","Epoch 00057: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1069 - acc: 0.9656 - val_loss: 0.5681 - val_acc: 0.8295\n","Epoch 58/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9399Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8209 - acc: 0.7917\n","Epoch 00058: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.2028 - acc: 0.9407 - val_loss: 0.8209 - val_acc: 0.7917\n","Epoch 59/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9425Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5426 - acc: 0.8523\n","Epoch 00059: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.1300 - acc: 0.9433 - val_loss: 0.5426 - val_acc: 0.8523\n","Epoch 60/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9784Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6766 - acc: 0.8447\n","Epoch 00060: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0595 - acc: 0.9770 - val_loss: 0.6766 - val_acc: 0.8447\n","Epoch 61/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9659Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6183 - acc: 0.8220\n","Epoch 00061: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 545ms/step - loss: 0.0837 - acc: 0.9663 - val_loss: 0.6183 - val_acc: 0.8220\n","Epoch 62/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9468Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6075 - acc: 0.8144\n","Epoch 00062: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 533ms/step - loss: 0.1455 - acc: 0.9475 - val_loss: 0.6075 - val_acc: 0.8144\n","Epoch 63/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9481Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9233 - acc: 0.7841\n","Epoch 00063: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 544ms/step - loss: 0.1258 - acc: 0.9487 - val_loss: 0.9233 - val_acc: 0.7841\n","Epoch 64/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2437 - acc: 0.9179Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6252 - acc: 0.7803\n","Epoch 00064: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.2458 - acc: 0.9157 - val_loss: 0.6252 - val_acc: 0.7803\n","Epoch 65/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1950 - acc: 0.9310Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6016 - acc: 0.8106\n","Epoch 00065: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 546ms/step - loss: 0.1926 - acc: 0.9319 - val_loss: 0.6016 - val_acc: 0.8106\n","Epoch 66/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9507Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5832 - acc: 0.8295\n","Epoch 00066: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.1482 - acc: 0.9514 - val_loss: 0.5832 - val_acc: 0.8295\n","Epoch 67/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9589Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5319 - acc: 0.8220\n","Epoch 00067: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.1380 - acc: 0.9595 - val_loss: 0.5319 - val_acc: 0.8220\n","Epoch 68/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9721Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6935 - acc: 0.8182\n","Epoch 00068: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0779 - acc: 0.9708 - val_loss: 0.6935 - val_acc: 0.8182\n","Epoch 69/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9787Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8126 - acc: 0.8295\n","Epoch 00069: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0566 - acc: 0.9789 - val_loss: 0.8126 - val_acc: 0.8295\n","Epoch 70/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9803Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8334 - acc: 0.8030\n","Epoch 00070: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0650 - acc: 0.9806 - val_loss: 0.8334 - val_acc: 0.8030\n","Epoch 71/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9518Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7545 - acc: 0.7917\n","Epoch 00071: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.1364 - acc: 0.9525 - val_loss: 0.7545 - val_acc: 0.7917\n","Epoch 72/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9545Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7847 - acc: 0.7955\n","Epoch 00072: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.1266 - acc: 0.9551 - val_loss: 0.7847 - val_acc: 0.7955\n","Epoch 73/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9655Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7563 - acc: 0.8295\n","Epoch 00073: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0954 - acc: 0.9643 - val_loss: 0.7563 - val_acc: 0.8295\n","Epoch 74/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9655Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9457 - acc: 0.8144\n","Epoch 00074: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.1030 - acc: 0.9660 - val_loss: 0.9457 - val_acc: 0.8144\n","Epoch 75/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1633 - acc: 0.9540Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8480 - acc: 0.8182\n","Epoch 00075: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1646 - acc: 0.9530 - val_loss: 0.8480 - val_acc: 0.8182\n","Epoch 76/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.8851Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.3322 - acc: 0.6856\n","Epoch 00076: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.2976 - acc: 0.8849 - val_loss: 1.3322 - val_acc: 0.6856\n","Epoch 77/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2384 - acc: 0.9261Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9985 - acc: 0.8106\n","Epoch 00077: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 547ms/step - loss: 0.2396 - acc: 0.9254 - val_loss: 0.9985 - val_acc: 0.8106\n","Epoch 78/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1949 - acc: 0.9245Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6342 - acc: 0.7803\n","Epoch 00078: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 545ms/step - loss: 0.1927 - acc: 0.9254 - val_loss: 0.6342 - val_acc: 0.7803\n","Epoch 79/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1892 - acc: 0.9458Epoch 1/300\n","33/78 [===========>..................] - ETA: 11s - loss: 0.6311 - acc: 0.8371\n","Epoch 00079: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 549ms/step - loss: 0.1901 - acc: 0.9449 - val_loss: 0.6311 - val_acc: 0.8371\n","Epoch 80/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1761 - acc: 0.9540Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7772 - acc: 0.7576\n","Epoch 00080: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 41s 528ms/step - loss: 0.1755 - acc: 0.9546 - val_loss: 0.7772 - val_acc: 0.7576\n","Epoch 81/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9458Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.4828 - acc: 0.8371\n","Epoch 00081: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.1597 - acc: 0.9465 - val_loss: 0.4828 - val_acc: 0.8371\n","Epoch 82/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9639Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7013 - acc: 0.8220\n","Epoch 00082: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.0803 - acc: 0.9643 - val_loss: 0.7013 - val_acc: 0.8220\n","Epoch 83/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9557Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7778 - acc: 0.8068\n","Epoch 00083: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1240 - acc: 0.9562 - val_loss: 0.7778 - val_acc: 0.8068\n","Epoch 84/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9704Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8750 - acc: 0.7955\n","Epoch 00084: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.0809 - acc: 0.9708 - val_loss: 0.8750 - val_acc: 0.7955\n","Epoch 85/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9803Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8072 - acc: 0.8182\n","Epoch 00085: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0664 - acc: 0.9806 - val_loss: 0.8072 - val_acc: 0.8182\n","Epoch 86/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9606Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8124 - acc: 0.7841\n","Epoch 00086: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1127 - acc: 0.9579 - val_loss: 0.8124 - val_acc: 0.7841\n","Epoch 87/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9770Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5982 - acc: 0.8447\n","Epoch 00087: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0743 - acc: 0.9773 - val_loss: 0.5982 - val_acc: 0.8447\n","Epoch 88/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9836Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8357 - acc: 0.8523\n","Epoch 00088: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0485 - acc: 0.9822 - val_loss: 0.8357 - val_acc: 0.8523\n","Epoch 89/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9754Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0205 - acc: 0.7992\n","Epoch 00089: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.0824 - acc: 0.9757 - val_loss: 1.0205 - val_acc: 0.7992\n","Epoch 90/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9754Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8004 - acc: 0.8106\n","Epoch 00090: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0637 - acc: 0.9741 - val_loss: 0.8004 - val_acc: 0.8106\n","Epoch 91/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9819Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7777 - acc: 0.8030\n","Epoch 00091: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0715 - acc: 0.9822 - val_loss: 0.7777 - val_acc: 0.8030\n","Epoch 92/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9967Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7833 - acc: 0.8523\n","Epoch 00092: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 544ms/step - loss: 0.0170 - acc: 0.9968 - val_loss: 0.7833 - val_acc: 0.8523\n","Epoch 93/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 1.0000Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9015 - acc: 0.8220\n","Epoch 00093: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 546ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.9015 - val_acc: 0.8220\n","Epoch 94/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9452Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6911 - acc: 0.8106\n","Epoch 00094: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.2052 - acc: 0.9459 - val_loss: 0.6911 - val_acc: 0.8106\n","Epoch 95/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3926 - acc: 0.8949Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8166 - acc: 0.7841\n","Epoch 00095: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 545ms/step - loss: 0.3878 - acc: 0.8963 - val_loss: 0.8166 - val_acc: 0.7841\n","Epoch 96/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9212Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6816 - acc: 0.8030\n","Epoch 00096: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.2120 - acc: 0.9206 - val_loss: 0.6816 - val_acc: 0.8030\n","Epoch 97/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9821Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5801 - acc: 0.8485\n","Epoch 00097: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.0745 - acc: 0.9824 - val_loss: 0.5801 - val_acc: 0.8485\n","Epoch 98/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.4118 - acc: 0.8754Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6972 - acc: 0.7500\n","Epoch 00098: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.4070 - acc: 0.8770 - val_loss: 0.6972 - val_acc: 0.7500\n","Epoch 99/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1685 - acc: 0.9327Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7534 - acc: 0.7955\n","Epoch 00099: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.1664 - acc: 0.9335 - val_loss: 0.7534 - val_acc: 0.7955\n","Epoch 100/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9672Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6243 - acc: 0.8258\n","Epoch 00100: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.1106 - acc: 0.9676 - val_loss: 0.6243 - val_acc: 0.8258\n","Epoch 101/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9672Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7672 - acc: 0.8447\n","Epoch 00101: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.0838 - acc: 0.9676 - val_loss: 0.7672 - val_acc: 0.8447\n","Epoch 102/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9708Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6936 - acc: 0.8295\n","Epoch 00102: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 545ms/step - loss: 0.0917 - acc: 0.9696 - val_loss: 0.6936 - val_acc: 0.8295\n","Epoch 103/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9585Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0066 - acc: 0.7992\n","Epoch 00103: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0958 - acc: 0.9574 - val_loss: 1.0066 - val_acc: 0.7992\n","Epoch 104/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9409Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0911 - acc: 0.7538\n","Epoch 00104: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.2211 - acc: 0.9400 - val_loss: 1.0911 - val_acc: 0.7538\n","Epoch 105/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9724Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7594 - acc: 0.8182\n","Epoch 00105: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.1038 - acc: 0.9728 - val_loss: 0.7594 - val_acc: 0.8182\n","Epoch 106/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9884Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7338 - acc: 0.8068\n","Epoch 00106: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0439 - acc: 0.9885 - val_loss: 0.7338 - val_acc: 0.8068\n","Epoch 107/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9688Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5924 - acc: 0.7992\n","Epoch 00107: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.0725 - acc: 0.9692 - val_loss: 0.5924 - val_acc: 0.7992\n","Epoch 108/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9819Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8049 - acc: 0.8068\n","Epoch 00108: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0482 - acc: 0.9822 - val_loss: 0.8049 - val_acc: 0.8068\n","Epoch 109/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9805Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6241 - acc: 0.8409\n","Epoch 00109: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 545ms/step - loss: 0.0504 - acc: 0.9808 - val_loss: 0.6241 - val_acc: 0.8409\n","Epoch 110/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9867Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6781 - acc: 0.8523\n","Epoch 00110: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0534 - acc: 0.9869 - val_loss: 0.6781 - val_acc: 0.8523\n","Epoch 111/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9836Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6998 - acc: 0.8409\n","Epoch 00111: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0453 - acc: 0.9822 - val_loss: 0.6998 - val_acc: 0.8409\n","Epoch 112/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9773Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8522 - acc: 0.8258\n","Epoch 00112: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.0617 - acc: 0.9776 - val_loss: 0.8522 - val_acc: 0.8258\n","Epoch 113/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9585Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9644 - acc: 0.7576\n","Epoch 00113: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.1113 - acc: 0.9590 - val_loss: 0.9644 - val_acc: 0.7576\n","Epoch 114/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3156 - acc: 0.9140Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8713 - acc: 0.7235\n","Epoch 00114: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 545ms/step - loss: 0.3352 - acc: 0.9087 - val_loss: 0.8713 - val_acc: 0.7235\n","Epoch 115/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2626 - acc: 0.8970Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.5864 - acc: 0.8220\n","Epoch 00115: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 533ms/step - loss: 0.2618 - acc: 0.8967 - val_loss: 0.5864 - val_acc: 0.8220\n","Epoch 116/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9704Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8175 - acc: 0.7992\n","Epoch 00116: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0832 - acc: 0.9692 - val_loss: 0.8175 - val_acc: 0.7992\n","Epoch 117/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9836Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8019 - acc: 0.8371\n","Epoch 00117: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0427 - acc: 0.9838 - val_loss: 0.8019 - val_acc: 0.8371\n","Epoch 118/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9951Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9944 - acc: 0.8144\n","Epoch 00118: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0155 - acc: 0.9951 - val_loss: 0.9944 - val_acc: 0.8144\n","Epoch 119/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9594Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7627 - acc: 0.8144\n","Epoch 00119: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.1153 - acc: 0.9599 - val_loss: 0.7627 - val_acc: 0.8144\n","Epoch 120/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9491Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7493 - acc: 0.8182\n","Epoch 00120: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.1283 - acc: 0.9498 - val_loss: 0.7493 - val_acc: 0.8182\n","Epoch 121/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9737Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6511 - acc: 0.8485\n","Epoch 00121: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.0685 - acc: 0.9741 - val_loss: 0.6511 - val_acc: 0.8485\n","Epoch 122/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9568Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7380 - acc: 0.8106\n","Epoch 00122: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 533ms/step - loss: 0.1219 - acc: 0.9557 - val_loss: 0.7380 - val_acc: 0.8106\n","Epoch 123/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9836Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.6634 - acc: 0.8182\n","Epoch 00123: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0557 - acc: 0.9838 - val_loss: 0.6634 - val_acc: 0.8182\n","Epoch 124/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9935Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.1415 - acc: 0.7955\n","Epoch 00124: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.0291 - acc: 0.9920 - val_loss: 1.1415 - val_acc: 0.7955\n","Epoch 125/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9900Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1384 - acc: 0.8106\n","Epoch 00125: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 533ms/step - loss: 0.0220 - acc: 0.9902 - val_loss: 1.1384 - val_acc: 0.8106\n","Epoch 126/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9852Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9906 - acc: 0.7879\n","Epoch 00126: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0466 - acc: 0.9854 - val_loss: 0.9906 - val_acc: 0.7879\n","Epoch 127/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9724Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.1079 - acc: 0.7841\n","Epoch 00127: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0875 - acc: 0.9728 - val_loss: 1.1079 - val_acc: 0.7841\n","Epoch 128/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9817Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0505 - acc: 0.8030\n","Epoch 00128: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0640 - acc: 0.9820 - val_loss: 1.0505 - val_acc: 0.8030\n","Epoch 129/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1453 - acc: 0.9507Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8398 - acc: 0.8030\n","Epoch 00129: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1434 - acc: 0.9514 - val_loss: 0.8398 - val_acc: 0.8030\n","Epoch 130/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9507Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8894 - acc: 0.8030\n","Epoch 00130: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.1403 - acc: 0.9498 - val_loss: 0.8894 - val_acc: 0.8030\n","Epoch 131/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9789Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.1272 - acc: 0.7879\n","Epoch 00131: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 545ms/step - loss: 0.0635 - acc: 0.9792 - val_loss: 1.1272 - val_acc: 0.7879\n","Epoch 132/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9639Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8479 - acc: 0.8220\n","Epoch 00132: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.1342 - acc: 0.9611 - val_loss: 0.8479 - val_acc: 0.8220\n","Epoch 133/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9606Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8149 - acc: 0.8144\n","Epoch 00133: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.1026 - acc: 0.9611 - val_loss: 0.8149 - val_acc: 0.8144\n","Epoch 134/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9901Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7805 - acc: 0.8258\n","Epoch 00134: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0395 - acc: 0.9903 - val_loss: 0.7805 - val_acc: 0.8258\n","Epoch 135/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9655Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8885 - acc: 0.7841\n","Epoch 00135: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.1139 - acc: 0.9660 - val_loss: 0.8885 - val_acc: 0.7841\n","Epoch 136/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9704Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6967 - acc: 0.8258\n","Epoch 00136: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0999 - acc: 0.9692 - val_loss: 0.6967 - val_acc: 0.8258\n","Epoch 137/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9606Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1658 - acc: 0.7689\n","Epoch 00137: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0959 - acc: 0.9611 - val_loss: 1.1658 - val_acc: 0.7689\n","Epoch 138/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9635Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7829 - acc: 0.8220\n","Epoch 00138: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.1063 - acc: 0.9639 - val_loss: 0.7829 - val_acc: 0.8220\n","Epoch 139/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9545Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7184 - acc: 0.8371\n","Epoch 00139: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.1230 - acc: 0.9551 - val_loss: 0.7184 - val_acc: 0.8371\n","Epoch 140/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9836Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7133 - acc: 0.7992\n","Epoch 00140: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0509 - acc: 0.9838 - val_loss: 0.7133 - val_acc: 0.7992\n","Epoch 141/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9869Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9805 - acc: 0.8182\n","Epoch 00141: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0353 - acc: 0.9870 - val_loss: 0.9805 - val_acc: 0.8182\n","Epoch 142/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9884Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6426 - acc: 0.8144\n","Epoch 00142: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0506 - acc: 0.9885 - val_loss: 0.6426 - val_acc: 0.8144\n","Epoch 143/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9805Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7955 - acc: 0.8447\n","Epoch 00143: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 552ms/step - loss: 0.0717 - acc: 0.9792 - val_loss: 0.7955 - val_acc: 0.8447\n","Epoch 144/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9917Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.1946 - acc: 0.8295\n","Epoch 00144: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 41s 532ms/step - loss: 0.0330 - acc: 0.9918 - val_loss: 1.1946 - val_acc: 0.8295\n","Epoch 145/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9773Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8923 - acc: 0.8447\n","Epoch 00145: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.0585 - acc: 0.9776 - val_loss: 0.8923 - val_acc: 0.8447\n","Epoch 146/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9751Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8817 - acc: 0.8220\n","Epoch 00146: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 533ms/step - loss: 0.0643 - acc: 0.9754 - val_loss: 0.8817 - val_acc: 0.8220\n","Epoch 147/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9497Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9571 - acc: 0.7727\n","Epoch 00147: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 546ms/step - loss: 0.1324 - acc: 0.9503 - val_loss: 0.9571 - val_acc: 0.7727\n","Epoch 148/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9704Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7383 - acc: 0.8258\n","Epoch 00148: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0865 - acc: 0.9708 - val_loss: 0.7383 - val_acc: 0.8258\n","Epoch 149/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9885Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8201 - acc: 0.8409\n","Epoch 00149: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0277 - acc: 0.9887 - val_loss: 0.8201 - val_acc: 0.8409\n","Epoch 150/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9901Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9409 - acc: 0.8409\n","Epoch 00150: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 544ms/step - loss: 0.0327 - acc: 0.9887 - val_loss: 0.9409 - val_acc: 0.8409\n","Epoch 151/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9951Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8161 - acc: 0.8333\n","Epoch 00151: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0115 - acc: 0.9951 - val_loss: 0.8161 - val_acc: 0.8333\n","Epoch 152/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9655Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0964 - acc: 0.7652\n","Epoch 00152: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.1058 - acc: 0.9643 - val_loss: 1.0964 - val_acc: 0.7652\n","Epoch 153/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2613 - acc: 0.9343Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7294 - acc: 0.7917\n","Epoch 00153: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.2628 - acc: 0.9319 - val_loss: 0.7294 - val_acc: 0.7917\n","Epoch 154/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9261Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7159 - acc: 0.8258\n","Epoch 00154: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.1637 - acc: 0.9271 - val_loss: 0.7159 - val_acc: 0.8258\n","Epoch 155/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9721Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6358 - acc: 0.8561\n","Epoch 00155: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0987 - acc: 0.9724 - val_loss: 0.6358 - val_acc: 0.8561\n","Epoch 156/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9885Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7330 - acc: 0.8371\n","Epoch 00156: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.0310 - acc: 0.9887 - val_loss: 0.7330 - val_acc: 0.8371\n","Epoch 157/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9557Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9606 - acc: 0.7765\n","Epoch 00157: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.1269 - acc: 0.9562 - val_loss: 0.9606 - val_acc: 0.7765\n","Epoch 158/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9787Epoch 1/300\n","33/78 [===========>..................] - ETA: 10s - loss: 0.7103 - acc: 0.8523\n","Epoch 00158: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.0625 - acc: 0.9789 - val_loss: 0.7103 - val_acc: 0.8523\n","Epoch 159/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9721Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7873 - acc: 0.8258\n","Epoch 00159: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 41s 524ms/step - loss: 0.0926 - acc: 0.9724 - val_loss: 0.7873 - val_acc: 0.8258\n","Epoch 160/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.4793 - acc: 0.8637Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.5747 - acc: 0.7992\n","Epoch 00160: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.4739 - acc: 0.8655 - val_loss: 0.5747 - val_acc: 0.7992\n","Epoch 161/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9507Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6201 - acc: 0.8598\n","Epoch 00161: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.1678 - acc: 0.9514 - val_loss: 0.6201 - val_acc: 0.8598\n","Epoch 162/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9918Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1509 - acc: 0.8106\n","Epoch 00162: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0295 - acc: 0.9919 - val_loss: 1.1509 - val_acc: 0.8106\n","Epoch 163/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9573Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8006 - acc: 0.7803\n","Epoch 00163: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1384 - acc: 0.9579 - val_loss: 0.8006 - val_acc: 0.7803\n","Epoch 164/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9787Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0543 - acc: 0.7803\n","Epoch 00164: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0737 - acc: 0.9789 - val_loss: 1.0543 - val_acc: 0.7803\n","Epoch 165/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9655Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.5949 - acc: 0.8409\n","Epoch 00165: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.1311 - acc: 0.9660 - val_loss: 0.5949 - val_acc: 0.8409\n","Epoch 166/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9803Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6962 - acc: 0.8333\n","Epoch 00166: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0448 - acc: 0.9806 - val_loss: 0.6962 - val_acc: 0.8333\n","Epoch 167/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9901Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9536 - acc: 0.8295\n","Epoch 00167: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0327 - acc: 0.9903 - val_loss: 0.9536 - val_acc: 0.8295\n","Epoch 168/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9951Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 2.1032 - acc: 0.7235\n","Epoch 00168: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0386 - acc: 0.9951 - val_loss: 2.1032 - val_acc: 0.7235\n","Epoch 169/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2355 - acc: 0.9261Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9554 - acc: 0.7652\n","Epoch 00169: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.2327 - acc: 0.9271 - val_loss: 0.9554 - val_acc: 0.7652\n","Epoch 170/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9606Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9161 - acc: 0.8106\n","Epoch 00170: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.1116 - acc: 0.9611 - val_loss: 0.9161 - val_acc: 0.8106\n","Epoch 171/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9740Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8156 - acc: 0.8371\n","Epoch 00171: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.0712 - acc: 0.9744 - val_loss: 0.8156 - val_acc: 0.8371\n","Epoch 172/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9918Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9047 - acc: 0.7917\n","Epoch 00172: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0298 - acc: 0.9919 - val_loss: 0.9047 - val_acc: 0.7917\n","Epoch 173/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9651Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6835 - acc: 0.8409\n","Epoch 00173: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 533ms/step - loss: 0.1237 - acc: 0.9656 - val_loss: 0.6835 - val_acc: 0.8409\n","Epoch 174/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9721Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0465 - acc: 0.7841\n","Epoch 00174: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0844 - acc: 0.9708 - val_loss: 1.0465 - val_acc: 0.7841\n","Epoch 175/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9819Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9344 - acc: 0.8258\n","Epoch 00175: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.0495 - acc: 0.9822 - val_loss: 0.9344 - val_acc: 0.8258\n","Epoch 176/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9903Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8058 - acc: 0.8485\n","Epoch 00176: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0349 - acc: 0.9904 - val_loss: 0.8058 - val_acc: 0.8485\n","Epoch 177/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2063 - acc: 0.9402Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8736 - acc: 0.7841\n","Epoch 00177: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 41s 532ms/step - loss: 0.2037 - acc: 0.9410 - val_loss: 0.8736 - val_acc: 0.7841\n","Epoch 178/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9754Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6696 - acc: 0.8258\n","Epoch 00178: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0670 - acc: 0.9757 - val_loss: 0.6696 - val_acc: 0.8258\n","Epoch 179/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9805Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8217 - acc: 0.8447\n","Epoch 00179: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0455 - acc: 0.9808 - val_loss: 0.8217 - val_acc: 0.8447\n","Epoch 180/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9900Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1070 - acc: 0.7917\n","Epoch 00180: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 41s 532ms/step - loss: 0.0306 - acc: 0.9902 - val_loss: 1.1070 - val_acc: 0.7917\n","Epoch 181/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9524Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9442 - acc: 0.8447\n","Epoch 00181: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.1449 - acc: 0.9514 - val_loss: 0.9442 - val_acc: 0.8447\n","Epoch 182/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9721Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8822 - acc: 0.8258\n","Epoch 00182: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0965 - acc: 0.9708 - val_loss: 0.8822 - val_acc: 0.8258\n","Epoch 183/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9821Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8659 - acc: 0.8333\n","Epoch 00183: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0448 - acc: 0.9824 - val_loss: 0.8659 - val_acc: 0.8333\n","Epoch 184/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9934Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0756 - acc: 0.8409\n","Epoch 00184: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0287 - acc: 0.9934 - val_loss: 1.0756 - val_acc: 0.8409\n","Epoch 185/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9836Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8980 - acc: 0.8295\n","Epoch 00185: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0541 - acc: 0.9838 - val_loss: 0.8980 - val_acc: 0.8295\n","Epoch 186/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9773Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8410 - acc: 0.8220\n","Epoch 00186: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.0465 - acc: 0.9776 - val_loss: 0.8410 - val_acc: 0.8220\n","Epoch 187/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9900Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.2139 - acc: 0.7879\n","Epoch 00187: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0186 - acc: 0.9902 - val_loss: 1.2139 - val_acc: 0.7879\n","Epoch 188/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9869Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9378 - acc: 0.8295\n","Epoch 00188: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0530 - acc: 0.9870 - val_loss: 0.9378 - val_acc: 0.8295\n","Epoch 189/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9918Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0221 - acc: 0.8523\n","Epoch 00189: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0340 - acc: 0.9903 - val_loss: 1.0221 - val_acc: 0.8523\n","Epoch 190/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2016 - acc: 0.9545Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7618 - acc: 0.7917\n","Epoch 00190: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.1996 - acc: 0.9551 - val_loss: 0.7618 - val_acc: 0.7917\n","Epoch 191/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9767Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7851 - acc: 0.8561\n","Epoch 00191: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0675 - acc: 0.9770 - val_loss: 0.7851 - val_acc: 0.8561\n","Epoch 192/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9901Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8174 - acc: 0.8485\n","Epoch 00192: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0267 - acc: 0.9903 - val_loss: 0.8174 - val_acc: 0.8485\n","Epoch 193/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9885Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0682 - acc: 0.8220\n","Epoch 00193: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0456 - acc: 0.9887 - val_loss: 1.0682 - val_acc: 0.8220\n","Epoch 194/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9918Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8693 - acc: 0.8258\n","Epoch 00194: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0302 - acc: 0.9919 - val_loss: 0.8693 - val_acc: 0.8258\n","Epoch 195/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9724Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8498 - acc: 0.8106\n","Epoch 00195: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.0794 - acc: 0.9728 - val_loss: 0.8498 - val_acc: 0.8106\n","Epoch 196/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9635Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9394 - acc: 0.8333\n","Epoch 00196: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.1105 - acc: 0.9623 - val_loss: 0.9394 - val_acc: 0.8333\n","Epoch 197/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9737Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7154 - acc: 0.8295\n","Epoch 00197: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0963 - acc: 0.9741 - val_loss: 0.7154 - val_acc: 0.8295\n","Epoch 198/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9740Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9587 - acc: 0.7803\n","Epoch 00198: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.0784 - acc: 0.9744 - val_loss: 0.9587 - val_acc: 0.7803\n","Epoch 199/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9869Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8466 - acc: 0.8295\n","Epoch 00199: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0359 - acc: 0.9870 - val_loss: 0.8466 - val_acc: 0.8295\n","Epoch 200/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9817Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0312 - acc: 0.8106\n","Epoch 00200: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 532ms/step - loss: 0.0812 - acc: 0.9820 - val_loss: 1.0312 - val_acc: 0.8106\n","Epoch 201/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9622Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6258 - acc: 0.8561\n","Epoch 00201: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.1358 - acc: 0.9627 - val_loss: 0.6258 - val_acc: 0.8561\n","Epoch 202/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9721Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8555 - acc: 0.8220\n","Epoch 00202: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0915 - acc: 0.9724 - val_loss: 0.8555 - val_acc: 0.8220\n","Epoch 203/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9838Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8875 - acc: 0.8144\n","Epoch 00203: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.0768 - acc: 0.9840 - val_loss: 0.8875 - val_acc: 0.8144\n","Epoch 204/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9885Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9400 - acc: 0.8409\n","Epoch 00204: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0254 - acc: 0.9887 - val_loss: 0.9400 - val_acc: 0.8409\n","Epoch 205/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9918Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.3807 - acc: 0.7955\n","Epoch 00205: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0311 - acc: 0.9919 - val_loss: 1.3807 - val_acc: 0.7955\n","Epoch 206/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3254 - acc: 0.9153Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7951 - acc: 0.7689\n","Epoch 00206: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.3358 - acc: 0.9148 - val_loss: 0.7951 - val_acc: 0.7689\n","Epoch 207/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9464Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6139 - acc: 0.8371\n","Epoch 00207: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1702 - acc: 0.9471 - val_loss: 0.6139 - val_acc: 0.8371\n","Epoch 208/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9751Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9439 - acc: 0.8068\n","Epoch 00208: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 41s 531ms/step - loss: 0.0633 - acc: 0.9754 - val_loss: 0.9439 - val_acc: 0.8068\n","Epoch 209/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9805Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7795 - acc: 0.8106\n","Epoch 00209: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.0496 - acc: 0.9808 - val_loss: 0.7795 - val_acc: 0.8106\n","Epoch 210/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9885Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9081 - acc: 0.8220\n","Epoch 00210: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0418 - acc: 0.9887 - val_loss: 0.9081 - val_acc: 0.8220\n","Epoch 211/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9901Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8386 - acc: 0.8068\n","Epoch 00211: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0345 - acc: 0.9903 - val_loss: 0.8386 - val_acc: 0.8068\n","Epoch 212/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9984Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8588 - acc: 0.8409\n","Epoch 00212: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0079 - acc: 0.9984 - val_loss: 0.8588 - val_acc: 0.8409\n","Epoch 213/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9884Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8304 - acc: 0.8258\n","Epoch 00213: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 532ms/step - loss: 0.0362 - acc: 0.9885 - val_loss: 0.8304 - val_acc: 0.8258\n","Epoch 214/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9919Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9656 - acc: 0.7992\n","Epoch 00214: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0369 - acc: 0.9920 - val_loss: 0.9656 - val_acc: 0.7992\n","Epoch 215/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9901Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9866 - acc: 0.8258\n","Epoch 00215: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0432 - acc: 0.9903 - val_loss: 0.9866 - val_acc: 0.8258\n","Epoch 216/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9784Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7950 - acc: 0.8030\n","Epoch 00216: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 532ms/step - loss: 0.0829 - acc: 0.9787 - val_loss: 0.7950 - val_acc: 0.8030\n","Epoch 217/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9773Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7638 - acc: 0.7879\n","Epoch 00217: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.0758 - acc: 0.9776 - val_loss: 0.7638 - val_acc: 0.7879\n","Epoch 218/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9934Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9969 - acc: 0.8144\n","Epoch 00218: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0262 - acc: 0.9935 - val_loss: 0.9969 - val_acc: 0.8144\n","Epoch 219/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9817Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8165 - acc: 0.8144\n","Epoch 00219: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 533ms/step - loss: 0.0529 - acc: 0.9820 - val_loss: 0.8165 - val_acc: 0.8144\n","Epoch 220/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9934Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8633 - acc: 0.8182\n","Epoch 00220: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0168 - acc: 0.9935 - val_loss: 0.8633 - val_acc: 0.8182\n","Epoch 221/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9805Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7765 - acc: 0.8144\n","Epoch 00221: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0587 - acc: 0.9808 - val_loss: 0.7765 - val_acc: 0.8144\n","Epoch 222/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9704Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7017 - acc: 0.8106\n","Epoch 00222: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.0940 - acc: 0.9708 - val_loss: 0.7017 - val_acc: 0.8106\n","Epoch 223/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9967Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7584 - acc: 0.8485\n","Epoch 00223: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0100 - acc: 0.9967 - val_loss: 0.7584 - val_acc: 0.8485\n","Epoch 224/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9919Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.6564 - acc: 0.7841\n","Epoch 00224: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0219 - acc: 0.9920 - val_loss: 1.6564 - val_acc: 0.7841\n","Epoch 225/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.2332 - acc: 0.9475Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9440 - acc: 0.7803\n","Epoch 00225: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.2312 - acc: 0.9481 - val_loss: 0.9440 - val_acc: 0.7803\n","Epoch 226/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1528 - acc: 0.9507Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8084 - acc: 0.7955\n","Epoch 00226: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.1509 - acc: 0.9514 - val_loss: 0.8084 - val_acc: 0.7955\n","Epoch 227/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9754Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8998 - acc: 0.8144\n","Epoch 00227: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0719 - acc: 0.9757 - val_loss: 0.8998 - val_acc: 0.8144\n","Epoch 228/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9721Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9276 - acc: 0.8030\n","Epoch 00228: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0584 - acc: 0.9724 - val_loss: 0.9276 - val_acc: 0.8030\n","Epoch 229/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9934Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8725 - acc: 0.8220\n","Epoch 00229: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0252 - acc: 0.9919 - val_loss: 0.8725 - val_acc: 0.8220\n","Epoch 230/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9770Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8174 - acc: 0.8371\n","Epoch 00230: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0671 - acc: 0.9773 - val_loss: 0.8174 - val_acc: 0.8371\n","Epoch 231/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9836Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8777 - acc: 0.8371\n","Epoch 00231: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0497 - acc: 0.9838 - val_loss: 0.8777 - val_acc: 0.8371\n","Epoch 232/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9918Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9172 - acc: 0.8182\n","Epoch 00232: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0303 - acc: 0.9919 - val_loss: 0.9172 - val_acc: 0.8182\n","Epoch 233/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9770Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.7270 - acc: 0.6818\n","Epoch 00233: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.1525 - acc: 0.9724 - val_loss: 1.7270 - val_acc: 0.6818\n","Epoch 234/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.3705 - acc: 0.8900Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7094 - acc: 0.7879\n","Epoch 00234: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.3688 - acc: 0.8914 - val_loss: 0.7094 - val_acc: 0.7879\n","Epoch 235/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9622Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.5615 - acc: 0.8371\n","Epoch 00235: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.1175 - acc: 0.9627 - val_loss: 0.5615 - val_acc: 0.8371\n","Epoch 236/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9836Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8859 - acc: 0.8106\n","Epoch 00236: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0545 - acc: 0.9838 - val_loss: 0.8859 - val_acc: 0.8106\n","Epoch 237/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9852Epoch 1/300\n","33/78 [===========>..................] - ETA: 10s - loss: 1.0628 - acc: 0.8106\n","Epoch 00237: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 542ms/step - loss: 0.0324 - acc: 0.9854 - val_loss: 1.0628 - val_acc: 0.8106\n","Epoch 238/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9754Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9192 - acc: 0.8030\n","Epoch 00238: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 41s 528ms/step - loss: 0.0652 - acc: 0.9757 - val_loss: 0.9192 - val_acc: 0.8030\n","Epoch 239/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9787Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0706 - acc: 0.7765\n","Epoch 00239: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0732 - acc: 0.9789 - val_loss: 1.0706 - val_acc: 0.7765\n","Epoch 240/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9754Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9645 - acc: 0.8258\n","Epoch 00240: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0619 - acc: 0.9757 - val_loss: 0.9645 - val_acc: 0.8258\n","Epoch 241/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9704Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.2854 - acc: 0.7803\n","Epoch 00241: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.1190 - acc: 0.9692 - val_loss: 1.2854 - val_acc: 0.7803\n","Epoch 242/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9901Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8559 - acc: 0.8258\n","Epoch 00242: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.0406 - acc: 0.9903 - val_loss: 0.8559 - val_acc: 0.8258\n","Epoch 243/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9819Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.5063 - acc: 0.7841\n","Epoch 00243: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.0422 - acc: 0.9822 - val_loss: 1.5063 - val_acc: 0.7841\n","Epoch 244/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9606Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0993 - acc: 0.7765\n","Epoch 00244: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.1683 - acc: 0.9611 - val_loss: 1.0993 - val_acc: 0.7765\n","Epoch 245/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9787Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8957 - acc: 0.8182\n","Epoch 00245: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0700 - acc: 0.9789 - val_loss: 0.8957 - val_acc: 0.8182\n","Epoch 246/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9787Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8823 - acc: 0.8144\n","Epoch 00246: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0602 - acc: 0.9789 - val_loss: 0.8823 - val_acc: 0.8144\n","Epoch 247/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9869Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.1507 - acc: 0.7803\n","Epoch 00247: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0452 - acc: 0.9870 - val_loss: 1.1507 - val_acc: 0.7803\n","Epoch 248/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9819Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0836 - acc: 0.8106\n","Epoch 00248: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0536 - acc: 0.9822 - val_loss: 1.0836 - val_acc: 0.8106\n","Epoch 249/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9852Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1270 - acc: 0.8258\n","Epoch 00249: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 546ms/step - loss: 0.0350 - acc: 0.9854 - val_loss: 1.1270 - val_acc: 0.8258\n","Epoch 250/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9655Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8612 - acc: 0.8106\n","Epoch 00250: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.1248 - acc: 0.9660 - val_loss: 0.8612 - val_acc: 0.8106\n","Epoch 251/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9869Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8360 - acc: 0.8258\n","Epoch 00251: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0296 - acc: 0.9870 - val_loss: 0.8360 - val_acc: 0.8258\n","Epoch 252/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 1.0000Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8785 - acc: 0.8409\n","Epoch 00252: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.8785 - val_acc: 0.8409\n","Epoch 253/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9967Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0352 - acc: 0.8371\n","Epoch 00253: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 533ms/step - loss: 0.0079 - acc: 0.9968 - val_loss: 1.0352 - val_acc: 0.8371\n","Epoch 254/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9803Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0240 - acc: 0.8068\n","Epoch 00254: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0814 - acc: 0.9789 - val_loss: 1.0240 - val_acc: 0.8068\n","Epoch 255/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9756Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1307 - acc: 0.7689\n","Epoch 00255: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.0811 - acc: 0.9760 - val_loss: 1.1307 - val_acc: 0.7689\n","Epoch 256/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9884Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.1595 - acc: 0.8220\n","Epoch 00256: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 533ms/step - loss: 0.0195 - acc: 0.9885 - val_loss: 1.1595 - val_acc: 0.8220\n","Epoch 257/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9967Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0549 - acc: 0.8409\n","Epoch 00257: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0079 - acc: 0.9968 - val_loss: 1.0549 - val_acc: 0.8409\n","Epoch 258/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 1.0000Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.2049 - acc: 0.8220\n","Epoch 00258: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.2049 - val_acc: 0.8220\n","Epoch 259/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9984Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0045 - acc: 0.8485\n","Epoch 00259: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0025 - acc: 0.9984 - val_loss: 1.0045 - val_acc: 0.8485\n","Epoch 260/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9934Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1323 - acc: 0.8258\n","Epoch 00260: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0220 - acc: 0.9935 - val_loss: 1.1323 - val_acc: 0.8258\n","Epoch 261/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9984Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.2505 - acc: 0.8333\n","Epoch 00261: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 543ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 1.2505 - val_acc: 0.8333\n","Epoch 262/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9951Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0060 - acc: 0.8485\n","Epoch 00262: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0135 - acc: 0.9951 - val_loss: 1.0060 - val_acc: 0.8485\n","Epoch 263/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9568Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0311 - acc: 0.7879\n","Epoch 00263: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.1808 - acc: 0.9574 - val_loss: 1.0311 - val_acc: 0.7879\n","Epoch 264/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9885Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8463 - acc: 0.8258\n","Epoch 00264: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 540ms/step - loss: 0.0332 - acc: 0.9870 - val_loss: 0.8463 - val_acc: 0.8258\n","Epoch 265/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9951Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.3338 - acc: 0.7841\n","Epoch 00265: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0198 - acc: 0.9951 - val_loss: 1.3338 - val_acc: 0.7841\n","Epoch 266/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9819Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.4302 - acc: 0.8068\n","Epoch 00266: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0510 - acc: 0.9822 - val_loss: 1.4302 - val_acc: 0.8068\n","Epoch 267/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9589Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.1304 - acc: 0.7386\n","Epoch 00267: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.1513 - acc: 0.9595 - val_loss: 1.1304 - val_acc: 0.7386\n","Epoch 268/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9737Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9804 - acc: 0.8068\n","Epoch 00268: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.0735 - acc: 0.9741 - val_loss: 0.9804 - val_acc: 0.8068\n","Epoch 269/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9951Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.3428 - acc: 0.7879\n","Epoch 00269: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0135 - acc: 0.9951 - val_loss: 1.3428 - val_acc: 0.7879\n","Epoch 270/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9589Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8625 - acc: 0.8182\n","Epoch 00270: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.1593 - acc: 0.9595 - val_loss: 0.8625 - val_acc: 0.8182\n","Epoch 271/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9789Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6837 - acc: 0.8447\n","Epoch 00271: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0801 - acc: 0.9792 - val_loss: 0.6837 - val_acc: 0.8447\n","Epoch 272/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9869Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9226 - acc: 0.8182\n","Epoch 00272: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0392 - acc: 0.9869 - val_loss: 0.9226 - val_acc: 0.8182\n","Epoch 273/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9773Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0066 - acc: 0.7917\n","Epoch 00273: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0917 - acc: 0.9776 - val_loss: 1.0066 - val_acc: 0.7917\n","Epoch 274/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9767Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1387 - acc: 0.7727\n","Epoch 00274: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.0712 - acc: 0.9770 - val_loss: 1.1387 - val_acc: 0.7727\n","Epoch 275/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9704Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.7792 - acc: 0.8182\n","Epoch 00275: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.1023 - acc: 0.9708 - val_loss: 0.7792 - val_acc: 0.8182\n","Epoch 276/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9967Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9155 - acc: 0.7955\n","Epoch 00276: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0171 - acc: 0.9968 - val_loss: 0.9155 - val_acc: 0.7955\n","Epoch 277/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9886Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9884 - acc: 0.8295\n","Epoch 00277: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.0222 - acc: 0.9888 - val_loss: 0.9884 - val_acc: 0.8295\n","Epoch 278/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9984Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8777 - acc: 0.8485\n","Epoch 00278: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0112 - acc: 0.9984 - val_loss: 0.8777 - val_acc: 0.8485\n","Epoch 279/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9967Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6699 - acc: 0.8598\n","Epoch 00279: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0062 - acc: 0.9968 - val_loss: 0.6699 - val_acc: 0.8598\n","Epoch 280/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9984Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8256 - acc: 0.8333\n","Epoch 00280: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.8256 - val_acc: 0.8333\n","Epoch 281/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9934Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.0941 - acc: 0.8144\n","Epoch 00281: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.0121 - acc: 0.9934 - val_loss: 1.0941 - val_acc: 0.8144\n","Epoch 282/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9773Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.6259 - acc: 0.8144\n","Epoch 00282: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0877 - acc: 0.9776 - val_loss: 0.6259 - val_acc: 0.8144\n","Epoch 283/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9688Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8469 - acc: 0.8447\n","Epoch 00283: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0813 - acc: 0.9692 - val_loss: 0.8469 - val_acc: 0.8447\n","Epoch 284/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9934Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.8060 - acc: 0.8106\n","Epoch 00284: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0171 - acc: 0.9935 - val_loss: 0.8060 - val_acc: 0.8106\n","Epoch 285/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 1.0000Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 0.9264 - acc: 0.8333\n","Epoch 00285: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.9264 - val_acc: 0.8333\n","Epoch 286/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9901Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1252 - acc: 0.7992\n","Epoch 00286: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.0332 - acc: 0.9903 - val_loss: 1.1252 - val_acc: 0.7992\n","Epoch 287/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9934Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0368 - acc: 0.8447\n","Epoch 00287: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 535ms/step - loss: 0.0250 - acc: 0.9934 - val_loss: 1.0368 - val_acc: 0.8447\n","Epoch 288/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9854Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1757 - acc: 0.8144\n","Epoch 00288: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.0740 - acc: 0.9840 - val_loss: 1.1757 - val_acc: 0.8144\n","Epoch 289/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9836Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.2649 - acc: 0.7917\n","Epoch 00289: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 541ms/step - loss: 0.0443 - acc: 0.9838 - val_loss: 1.2649 - val_acc: 0.7917\n","Epoch 290/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9901Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9722 - acc: 0.7992\n","Epoch 00290: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 546ms/step - loss: 0.0453 - acc: 0.9903 - val_loss: 0.9722 - val_acc: 0.7992\n","Epoch 291/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9885Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.4104 - acc: 0.7917\n","Epoch 00291: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0277 - acc: 0.9887 - val_loss: 1.4104 - val_acc: 0.7917\n","Epoch 292/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9885Epoch 1/300\n","33/78 [===========>..................] - ETA: 8s - loss: 1.1577 - acc: 0.8220\n","Epoch 00292: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.0397 - acc: 0.9887 - val_loss: 1.1577 - val_acc: 0.8220\n","Epoch 293/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9885Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.9245 - acc: 0.8295\n","Epoch 00293: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 537ms/step - loss: 0.0276 - acc: 0.9887 - val_loss: 0.9245 - val_acc: 0.8295\n","Epoch 294/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9901Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0982 - acc: 0.8258\n","Epoch 00294: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 538ms/step - loss: 0.0515 - acc: 0.9887 - val_loss: 1.0982 - val_acc: 0.8258\n","Epoch 295/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.5253 - acc: 0.8654Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7108 - acc: 0.8030\n","Epoch 00295: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 539ms/step - loss: 0.5179 - acc: 0.8671 - val_loss: 0.7108 - val_acc: 0.8030\n","Epoch 296/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9635Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.7494 - acc: 0.8106\n","Epoch 00296: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 534ms/step - loss: 0.1230 - acc: 0.9639 - val_loss: 0.7494 - val_acc: 0.8106\n","Epoch 297/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9721Epoch 1/300\n","33/78 [===========>..................] - ETA: 11s - loss: 0.8614 - acc: 0.8068\n","Epoch 00297: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 44s 564ms/step - loss: 0.1060 - acc: 0.9724 - val_loss: 0.8614 - val_acc: 0.8068\n","Epoch 298/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9708Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8712 - acc: 0.7803\n","Epoch 00298: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 547ms/step - loss: 0.0964 - acc: 0.9712 - val_loss: 0.8712 - val_acc: 0.7803\n","Epoch 299/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9754Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 0.8943 - acc: 0.8220\n","Epoch 00299: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 42s 536ms/step - loss: 0.0885 - acc: 0.9757 - val_loss: 0.8943 - val_acc: 0.8220\n","Epoch 300/300\n","77/78 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9951Epoch 1/300\n","33/78 [===========>..................] - ETA: 9s - loss: 1.0052 - acc: 0.8144\n","Epoch 00300: saving model to vgg16_model_weights.h5\n","78/78 [==============================] - 43s 555ms/step - loss: 0.0142 - acc: 0.9951 - val_loss: 1.0052 - val_acc: 0.8144\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDw8PjwbH/w9L3urUrRvG4QAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"jIn8BW8LGJ8A","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}