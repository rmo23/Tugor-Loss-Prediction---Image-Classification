{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy_of_soybean_pred_turgor_loss.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RA5JbpIx9g-X","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iU2tJS3q9ttx","colab_type":"code","outputId":"1bc052ea-c138-4bdd-86f6-7b821347b528","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b98mcIJ-BF7L","colab_type":"code","outputId":"8d340100-d3cd-43b6-d331-31afc0b1bc6e","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from keras import backend as K \n","from keras.preprocessing.image import ImageDataGenerator \n","from keras.models import Sequential \n","from keras.layers import Conv2D, MaxPooling2D \n","from keras.layers import Activation, Dropout, Flatten, Dense \n","! pip install split-folders\n","\n","import split_folders"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Collecting split-folders\n","  Downloading https://files.pythonhosted.org/packages/20/67/29dda743e6d23ac1ea3d16704d8bbb48d65faf3f1b1eaf53153b3da56c56/split_folders-0.3.1-py3-none-any.whl\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yzj_ajZ1DqgP","colab_type":"code","outputId":"a9f49736-e1c7-4365-ed20-7808086dfeb8","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Split the data into training and validation\n","training_data_folder = \"/content/drive/My Drive/NN-ProjectC/Project_C1/Training\"\n","split_folders.ratio(training_data_folder, output = \"train_val_test\", seed=1337, ratio = (.6,.3,.1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Copying files: 4476 files [32:58,  2.28 files/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0ax3b0gv9u0Q","colab_type":"code","colab":{}},"source":["# Data Initialization\n","import os\n","\n","# ! unzip \"train_val.zip\"\n","train_data_dir = \"train_val_test/train\"\n","val_data_dir = \"train_val_test/val\"\n","num_train = 0\n","num_val = 1344\n","\n","# for i in os.listdir(train_data_dir):\n","#   num_train += len(os.listdir(os.path.join(train_data_dir, i)))\n","\n","\n","img_width, img_height = 224, 224\n","# Check if the images are RGB and change the channels likewise\n","if K.image_data_format() == 'channels_first':\n","  input_shape= (3, img_width, img_height)\n","else:\n","  input_shape = (img_width, img_height, 3)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIv8wm46PB8v","colab_type":"code","colab":{}},"source":["\n","# CNN model\n","model = Sequential()\n","model.add(Conv2D(32,(2,2), input_shape = input_shape))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","\n","model.add(Conv2D(32,(2,2)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","\n","model.add(Conv2D(64,(2,2)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2,2)))\n","\n","model.add(Flatten())\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(5))\n","model.add(Activation('softmax'))\n","\n","model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftnKFUTxPavT","colab_type":"code","colab":{}},"source":["batch_size = 64\n","epochs = 50\n","\n","train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2)\n","train_generator = train_datagen.flow_from_directory(train_data_dir, target_size =(img_width, img_height), batch_size = batch_size, class_mode = 'categorical')\n","validation_generator = train_datagen.flow_from_directory( val_data_dir, target_size =(img_width, img_height), batch_size = batch_size, class_mode ='categorical') \n","\n","model.fit_generator(train_generator, steps_per_epoch = num_train // batch_size, epochs = epochs, validation_data = validation_generator, validation_steps = num_val// batch_size)\n","\n","model.save_weights(\"v1_1.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xc0eQjw_SVmF","colab_type":"code","colab":{}},"source":["! zip -r \"/content/train_val_test.zip\" \"/content/train_val_test\"\n","test_set_dir = \"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"saXgFoeuTSor","colab_type":"code","outputId":"2e703264-1286-4b35-8960-a26523eba31d","colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["#  ! unzip \"/content/drive/My Drive/NN-ProjectC/Project_C1/train_val_test.zip\"\n","import numpy\n","import sklearn.metrics as metrics\n","img_width, img_height = 224, 224\n","batch_size = 64\n","epochs = 50\n","\n","test_set_dir = \"/content/content/train_val_test/test\"\n","\n","num_test = 0\n","for i in os.listdir(test_set_dir):\n","  num_test += len(os.listdir(os.path.join(test_set_dir, i)))\n","\n","print (\"Number of images in test set: \", num_test)\n","\n","model.load_weights(\"/content/drive/My Drive/NN-ProjectC/Project_C1/Models/v1_1.h5\")\n","  \n","test_datagen = ImageDataGenerator(rescale=1./255)\n","test_generator = test_datagen.flow_from_directory(test_set_dir, target_size =(img_width, img_height), \n","                                                  batch_size = batch_size, class_mode ='categorical') \n","# scoreSeg = model.evaluate_generator(test_generator, num_test // batch_size)\n","# scoreSeg[1]\n","\n","test_steps_per_epoch = numpy.math.ceil(test_generator.samples / test_generator.batch_size)\n","\n","predictions = model.predict_generator(test_generator, steps = test_steps_per_epoch)\n","# Get most likely class\n","predicted_classes = numpy.argmax(predictions, axis=1)\n","true_classes = test_generator.classes\n","print (len(predicted_classes))\n","print (len(true_classes))\n","class_labels = list(test_generator.class_indices.keys()) \n","report = metrics.confusion_matrix(true_classes, predicted_classes, labels=[0,1,2,3,4])\n","print(report)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of images in test set:  450\n","Found 450 images belonging to 5 classes.\n","450\n","450\n","[[95 42 31 32 19]\n"," [38 12 10 10  7]\n"," [34  6  7  5  5]\n"," [30  7  8 11  3]\n"," [17 11  4  3  3]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M_gJf3CnUgGz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}